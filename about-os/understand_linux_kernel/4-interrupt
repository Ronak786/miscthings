interrupts: caused by outside device, mostly async
exception: caused by internal instrument executing, mostly sync

pic: programmable interrupt controller:
	8259a: each irq line connect one dev, when occurred interrupt,
		pic save line number in it, assert cput pin, then cpu can
		handle and know which number
		used for uniprocessor
	apic:
		local apic embeded in each smp cpu
		io apic connect to dev and on a bus to all local apic,
			io apic has a route table, 
			can staticly decide which cpu to send interrupt,
			or depend on process priority current running on 
			cpu the decide the lowest one to send, priority
			set by linux
			if same priority, use round-robin

	outer interrupt n ==> interrupt vector n+32 in idt table(each 8bytes)
	inner exception and nmi and fault use lower 32 numbers
		each exception has one handle for it

	cpu use IDT use handle all interrupts, int it , we have
		trap gate (for exceptions)
		interrupt gate( for interrupts)
	when interrupt happen:
		every instrument executed after, check interrupt and exception,
		if happened, search idt for gate, in idt is segment descriptor
		of gdt,  so search that,  and check priority

		if priority change happened, store and get another kernel stack
		from tss, save old one on new stack, 
		if it is a fault, save cs ip as the fault instrument so can 
		execute again,
		store cs ip flags on stack
		save error code
		run exception handler,

		restore cs ip eflags, return status of error code
		if priority change, restore stack
		check es fs gs  ds, if containe kernel segment, clear them
		for security issue

nest:
	interrupt can be nested, and should not block

initialize:
	in arch/i386/kernel/entry.S
	int setup_irq() set up 256 of dummy irqs
	and in trap_init() set up specific for each exception, 
		outside interrupt are set in each driver
		set done by descriptor set in idt pointer to gdt's index
		int 8 (double fault) is special, not depend on stack which may be correupt,
			just jump to a special tss segment

exception handler:
	mostly push into stack error code and the do_handler_name() func and 
	call error_cmd func and call the handler, which mostly will just set correspongding 
	process's signal status, 
	when return ,ret_from_exception() , process run again and check signal pending and do with that
		this is immediately which different from interrupt which far from process

interrupt handling:
	io interrupt: device related
		share: every time interrupt come, search each func on same request line 
		dynamic alloc: every time only one dev attach onit ,but others can also do with it 
			when this dev detach

		only critical work and update of data struct should be done here, copy  issue should 
			in tasklet

		common procedure:
			save irq value and regs, send acknowledge to pic, run handler, terminate to ret_from_intr()

		interruptvectors:
			128 used to syscall tranditaionally, others >= 32 can assign arbitraly
			in linux ibm pc: interval timer be  irq0, slave pic be irq2
			0-19 nonamskable
			20-31 intel reserved
			32-127 external interrupt
			128 syscall
			128-238 external interrupt
			239 240 254 255 local apic related
			251-253 interprocessor interrut
			241-250 linux reserved

			how to get interrupt:
				1 by hardware jumper
				2 by some probe method
				3 by auto config bus such as pci

			init_IRQ() will set up interrupts dummyed in setup_idt()

			in irq_desc array, we have a irq_desc_t in each entry, 
				each corresponding to one interrupt line, have a handler for hardware ops(enable ,disable, ack, close..)
				and a list of software handler, and other status(inprogress, disable, pending), count, lock depth
			in irq_action:
				handler: routine 
				flag: shirq or, interrupt(shoud disable while handling)
				dev_id:private data
				irq: /proc/irq/num directory
				next: next link
				name
			irq_stat:
				array of cpunumbers, each cpu's irq status(soft pending.. apic count, nmi count)

			distribute irqs among cpus:
			apic:
				setup_io_apic_irqs(): used to set interrupt route table for faily delieve interrupt among all cpus
				setup_local_apic(): set priority register to a fix value, so round-robin
			kirqd:
				if apic can not work well for some cpu
				if use do_irq_balance() to handle /proc/irq/n/smp_affinity by using set_ioapic_affinity_irq()
					for some cpu some irq number to make balance

			mutiple kernel stacks:
				if thread_info is 8kb page, exception stack hard irq stack softirq stack are the same and 
					use this page
				if is 4kb, then exception stack is currnet->thread_union's recorded stack
								hardiqr, softirq are in cpu arrays of hardirq_array, softirq_array
								each cpu has one of these, so stack share on all process running on one cpu
								and each cpu has a thread_info struct(not a process thread_info but same struct)

			how interrupt handled:
				after init_IRQ(), then interrupt occurred, see above "when interrupt happen:", after
					save cs ip ss sp  eflags .., 
				all handler first: 
					push $n-256 ;; all interrupt num is minus, save positive for syscalls
					jmp common_interrupt
				common_interrupt:
					SAVE_ALL ;; save all other regs interrupt will use, save user data stack into  ds, es
					mov esp, eax ;; now save stack top
					call do_IRQ  ;; do truly irq job
					jmp ret_from_intr

				do_IRQ:
					irq_enter()  increase interrupt count for nest 
					if thread size is 4kb
						use esp get current interrupted process's thread_info
						pick out from hardirq_array your cpus hard stack
						if compare same ,nest irq, so just continue next step;
						else switch to hard stack, set current thread_info and 
							current esp into hard stack's thread_info(& mask 4k)
							and load hardirq stack(now stack changed ,current macro
									also work well)
					invoke __do_irq() for with regs and irqnum as parm
					switch back irq stack for nest irq and exception if  needed(above if statement)
					irq_exit() decrease count and check softirq is waiting
					ret_from_intr()
				__do_irq:
					acknowledge interrupt and set pending status,
					then in a loop set inprogress status and  handle_irq_events
					end interrupt (notify apic or pic)
					
					note: usually interrupt is disabled by acknowledge when handle interrupt,
						but board may behavior errorly or other cpu is handling same interrupt,
						so pending should be checked multiple times to handle serially interrupts
						on just one handler
				handle_irq_events:
					for each action, run it, if all action return 0, add count to unexpected interrupts
					if SA_INTERRUPT flag not set, enable interrupt

				if dynamic handle:
					in init func: request_irq, 
					int exit func: free_irq
					
					
						

	timer interrupt: timer related
	interprocessor interrupt
		send and receive by apic, used to tell other cores to do some function, do reshedule, do cacheinvalidation
		send_IPI_all() ...

preempt_count:
	increased when enter_irq(),so schedule not possible, until self called schedule to release cpu
	in thread_info [0-7] preempt_count( 0 means can preempt) [8-15] soft irq count, [16-27] hardirq count,
				28 PREEMPT_ALIVE flag, nonzero all means can not preempt

softirq and tasklet:
	irq_stat array: softirq_pending used to decide on current cpu pending softirqs, use local_softirq_pending() to check
	softirq are jobs done at some checkpoint, or in ksoftirqd, but all should be in interrupt context,
		(ksoftirqd will disable irq), and can not sleep, but can be interrupted 
		softirq is reenterent and can be call multiple cores together
		softirq_vec[] has 6 members of softirq_action
	tasklet are two member  in softirq, driver developers should use this instead of softirq
		tasklet can only be run on one cpu,(use cache advantage), and schedule tasklet only run on the cpu
			schedule it

	handle softirq:
		raise_softirq(): pend it
			store flags and disable irq
			mark pending in pending mark,
			if in_interrupt() (softirq disabled or raise_softirq is running), nothing to do
			else wakeup_softirq() to wakeup ksoftirqd
			restore irq flags

		someplaces for check softirq should run(): and do_softirq() is called
			local_bh_enable()
			do_IRQ()->irq_exit()
			timer interrupt
			ipi interrupt 
			ksoftirqd/n is waken

		do_softirq():
			if in_interrupt() -> is running another instance or disabled, just return
			disable irq and change stack 
			__do_softirq()
			enable and restore stack
		__do_softirq()
			local_bh_disable() to increaset softirq count in preempt_count
			get bitmap pending list
			disable irq 
			clear bitmap
			enable irq
			for each pending in bitmap, call irq func
			disable irq
			copy bitmap ....  do this a fix iteration times,
			if still has pending jobs,  call wakeup_softirq to the ksoftiqrd to handle it, then substract softirq count
		ksofrirqd:
			have low priority, keep scheduleing and wakeup disable irq, run do_softirq; enable irq

		tasklet:
			schedule:
				schedule_tasklet() : will pend to the tasklet list for that cpu
				and raise_softirq_irqoff
			run:
				if running on other cpu(flag schedule_run is set), reinsert into list for next run
				else set run flag
				if  disabled, clear run flag, reinsert and activate again
				clear tasklet_sched flag and run it

	workqueue: can sleep
		each queue have on each cpu one thread,one cpu_workqueue struct containing a worklist,
			use insert_queue, remove_queue to maintain flush_workqueue() (only work queued before this call
					made sure to finish when this call is returned)
		default workqueue:
			schedule_[delayed_]work()
			flush_scheduled_work()

	work:
		has a pending for exist check in queue,  a timer for delayed work(just in timer handler insert into queue)
		work thread resume may in a different cpu, so may run work on different cpus


return from exception and irq:
	thread_info's flag has reschedule request, sigpending... other flags to check when return
	seperated return to kkernel, returnn to userspace
	check cs from stack:
	return to kernel:
		check preempt_count, if 0, do schedule check
							else, pop registers and iret to interrupted process
		in schedule check:
			if no schedule request or in local irq disable status, just pop register and return
			else reschedule another process, after back, locak irq, check again ,if need, contine schedule ...
	return to userspace
			if need schedule, do schedule, then resume current progress
