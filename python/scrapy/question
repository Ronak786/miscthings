in scrapyd  webservice.py class Cancel used to cancel a job
in spiderkeeper app/proxy/contrib/scrapy.py, cancel_spider will send that cancel post request,
	you can also send yourself using 
		curl http://192.168.202.122:6800/cancel.json -d project=kof -d job=56f65670501711e7a324000c2934ef85,
			this get from http://192.168.202.122:6800/, is scrapyd's webpage,
	Spiderkeepr的取消其实是有用的，但是gracefully stop will cost a lot of time

	this is a graceful cancel, so will last for a very long time to truly stop

	app/spider/controller.py 有一个upload相关的函数

debug:
	just using logging.warning() this is useful
	app/spider/controller.py  job_stop    not work, use system(curl)
		明天再看一下，cancel的时候哦的最后一项，是不是curl,还是其他的

启动的时候有时候会报错，openssl 符号导入错误，
	查证应该是cryptography　这个模块，scrapyd 用pip 安装，自带scrapy ,但这个自带的和pip里的cryptography是不兼容的，
		要用conda install的cryptography

安装：
	创建ｃｏｎｄａ环境，　conda install cryptography, pip install scrapyd,  pip install spiderkeeper, pip install scrapyd-client
