isa： 指令集架构体系，这个是cpu对外的抽象接口，包括了怎样操作cpu的方法
	这意味这一个编程的生态环境，所以这个的通用性很重要
微架构： 这个是上层isa的具体实现设计，
底层物理设计，这个是支持微架构的具体实现

现在来说，接口，面积，功耗，性能是评判标准

CISC名词的出现是因为后来risc的出现，为了区别
	risc 是因为复杂指令反倒很少被编译器用到，所以边长反倒浪费cpu频率

cisc：intel早期使用，性能有瓶颈，后来在p6微架构里改为转换成类risc的微指令，
	实现了risc的效率，虽然略复杂，后来risc由于指令过于繁琐，也反过来增加了
	少量的边长指令，两者相互融合

指令集种类（定义了生态圈）
x86:1978年第一款 其他都是八十年代了
	tick tock  指两年一次升级，第一年芯片制程，增加晶体管数量，第二年微架构工艺，
				决定晶体管的排放， 这样迅速提升

arm;
	也是80年代就有的处理器，有点是功耗低，适合移动产品，所以可以到现在

mips
	学术优雅的指令集，但是商业上决策失误，功耗，性能两边找错对手，失败，
		目前和arm一样出售指令集过活，在少量领域方面有使用，同时在教学上
		有很大又是:

power:
	当初联合AIM 对抗Wintel， 后来生态圈不够，失败，目前仍然联合自身的所有
	power相关，主要是服务器游戏机上的业务

dsp:
	c6000 这个是通信行业使用的指令集以及处理器， 由ti（德州仪器）公司以及lsi等使用

处理器指标:
字长： 32 64, amd 首先推出x86架构的64位
操作数个数： mips是三个， x86 不一定
指令类型：
	算数逻辑指令： 运算符
	控制指令： if while 。。。
	数据传送指令： 在risc中
	寻址方式：立即数寻址（可以指数和寄存器的值相加做值， 也可以取括号来得到那个作为地址的内存里的值）

微架构相关：
	流水线： 
		n级流水线指的是流水线中的步序是多少
		经典的５级流水线：　取指令， 译码， 执行， 读写内存 ，读写寄存器， 完成一条汇编的任务
			其中入载入操作，就是执行阶段计算地址，读写内存阶段执行读入
		可能的问题：
			流水线上两部分都要访问内存，产生延迟，流水线冒险， 现在因为指令数据缓存分开了，所以没事
			流水线上前一条指令的值被后一条访问，单前一条还没到可以写入的步骤，采取延迟+直通（直接从运算逻辑
				ALU出口通向后一条的必须的入口）的方法来避免
			分支预测：可以是根据上次跳转与否判断
					根据一个跳转表记录
					根据统计的结果
		乱序执行：
			执行互不相关的指令的时候，适当调换顺序来加速
			寄存器的相关：存在伪相关，就是由于通用寄存器的不够而使用了
						同样的寄存器，导致不能并行
			数据相关可以通过重编程优化，把相关性语句减到最小
			控制相关可以预测（统计），
			重新映射寄存器改变

			指令buffer， 用于缓存要乱序的指令，用来调度以及解决依赖问题
			重排序buffer，执行完后，要按顺序提交到isa的寄存器上，这样才能防止
					由于中断引起的寄存器可能的不一致（由乱序超前执行导致）

		超标量：
			通常的串行输入后，处理其内部做并行优化
		vliw：
			编译器级别的并行指示，然后cpu直接执行是否并行

		超标量：
			前端负责译码取指令，后端负责乱序控制和执行，为了超标量，
				也需要提前译码
				trace cache存放微操作的操作码，这是流水线后端的执行顺序
				所谓发射，就是多条同时译码，乱序执行则是后端的调度根据译码的结果
					回避相关性后的选择执行，还要buffer保存顺序
					而执行单元内部由多个各种类型执行的小单元，用于并行执行各种任务，
					最后是寄存器和内存的更新操作，最后是把所有这些都反映到isa级别的寄存器上

		VLIW:
			这个在编译的时候选择如何优化指令的输入，到时候cpu直接就是多条指令打一个包整体进行
			译码，操作，输出的，x86由于以前的包袱，不能做这种不兼容的更新

	simd:
		这是一类指令，包括sse  mmx等，都是用来一个指令中处理多组数据间的相同操作的，
			常用于多媒体采样处理中

	硬件多线程：
		硬件发现cachemiss的时候，切换到另一个线程上运行
		SMT 同时多线程，即发射指令处于不同的线程时，属于超线程执行
		（但是线程切换是操作系统控制的，难道这里是不适用linux的schedule函数，
		内部直接自己选择调度吗？那不是乱套了吗？？）
			应该是对于操作系统呈现超线程之后的多个核，内部自己超线程，
			在os看来却是多个cpu在处理，所以os感知不到，却永远按最多来操作

	多核：
		多核需要通信，所以会有总线式，两两互联式，矩阵式，环形式的通信方式

	提高效率的方法：
		减少程序的指令数==单指令处理多数据
		增加每个周期的指令数==减少每条指令使用的周期
		减少周期的时间==增加频率

	功耗：
		乱序会增加功耗，其他技术会减少，为了功耗，有时会舍弃乱序，新处理器用vliw

	cache:
		时间局部，空间局部
		cache line:
			full: 将内存空间分为cacheline大小的单元，每次寻找要全比较
			direct line: 内存分为cache 大小的单元，每个单元里面每一行都固定对应cache中一个位子
						这样内存中所有地址都固定在某个行上了，好找，但是容易miss
			set: 每个几个cacheline组成一个set，同样的cache set命中都放在一个set里面，这样查找较少，
					又不会过于轻易换出

		write through
		write back 后者可以暂时缓存在cache而不写回
			
		多核cache的一致性问题：
			如果一个cache更改，其他的都要置为无效或者同步更新，无效比较高效
			实际有一个MESI协议用于规范核间通信，各个核的cache状态的改变以及
			修改数据的获取由这个定义，也成为snoop协议（监听）

		cache dma：
			存在可寻址的cache，供程序员控制手动加载cache（dma方式）来加速
			这个在ti（德州仪器）的dsp处理器上多见

	优化程序：
		减少指令
		高效算法
		选择合适的指令：比如汇编，编译器提供的汇编式函数，C
		使用低精度函数
		减少函数调用
		空间换时间： 提早准备好，直接给你
		减少不必要的异常检测，
		改写简单的指令替换复杂的
		浮点定点化
		分支 尽量放在if里面

		少使用数组，指针，多使用局部变量，容易放进cache
		少用全局变量（不会进cache，大家会用到）
		数据对齐
		cache对齐结构体
		代码频繁使用的聚集
		多线程编程 少共享，不同的数据不要共享到相同的line
		自己管理内存分配

	编译器优化：
		restrict  指针唯一，所以可以优化
		指令级优化，
		openMP
			并行优化的编译器指示

	多线程编程  锁的必要
soc：
	片上系统，就是由多余一个ip（独立逻辑系统，比如一个cpu）核存在的芯片
	现在的设计就是每个公司负责一个流程，从ip到半导体芯片设计，到代工制造，
	到设备，到用户
Xtensa: (书： 复杂Soc设计）
	可配置的ip核，设计处理器更加简单了
硬件加速器：
	就是专门某种功能的硬件电路，专门ip核

	各种ip core组成了基本电路的功能，才会有上层的cpu
	处理器代码也开源， 如openrisc

信号的转换：
	物理信号==》传感器==》模拟信号 ==》采样，量化，编码==》数字信号
	组合逻辑电路：输入立刻决定输出，无延时
	时序逻辑电路： 还有一个D触发器，会在时钟边沿改变，这样就可以以时钟为单位
				保存/改变 输出值了
	晶体管：单向导电材料设计而成的电子元件
	集成电路：晶体管放在一块板上
抽象：(系统设计 逐步细化，最后实现）
	isa 微架构 cache 都是设计，都是一种抽象
	cpu的设计也包括系统 逻辑单元， 逻辑门层， 晶体管层
	模块间的独立很重要，一个ip核就是一个模块

eda： 电子设计自动化（完成集成电路设计）
	hdl 硬件描述语言，设计出寄存器级别的电路，然后综合生成netlist 门级网表（门电路级别的图）
	处理器的设计需要从晶圆的提炼，制作成型，到切割电路，到封装成片，这是物理上的，
		逻辑上要从系统级别到门级别到电路级别的设计图，才可以最终流片
