get source , from git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git
	then you can git pull to get the newest everytime

patch:   patch -p1 < ../xxxxx.patch

CONFIG_IKCONFIG_PROC to have /proc/config.gz
	use zcat to cat and redirect into file

about compile:
	use make > /dev/null to omit normal output
	use distcc  and ccache  and make -jn to imporve the efficiency of compile

c libs:
	use  self contrusted  c libs 

inline funcs:
	static inline XXX ,  safe  readability than  macros , 

inline assembly
	asm volatile(XXX)

likely and unlikely:
	help kernel to optimise

no mem protection
kernel stack  : 
	fixed size , not dynamically

sync and protection of race

process  fork  -> clone

every process has a process descriptor -- a structure
	in which we have a struct thread_info  , at fixed place of the descriptor
	in which we have a pointer of task_struct  ,we will refer to this frequently 
	the process descriptor is just under the kernel stack of each process
		and I think should be 8k alligned ( 64bit ， 4k when 32bit)

about process's status
	uninterruptible means :
		in sleep 
		the sleep can not be interrupted ; then can not be cancelled
		

we traverse by  next and prev of struct task_struct or the macro of process iterator

when creating , we use fork and exec when needed , we insist  copy on write , so only  the page table and a process descriptor
	needed to be created when fork , then all pages read only , before any write happens , that time , we alloc a new page

fork/vfork/_clone -> clone(pass in flags identifies which resoruce to share)  -> do_fork -> copy_process
	in copy_process :
		copy the process strcuct , 
		check not overflow the maxmum size of processes of the usef
		set condition to uninterruptible
		set flags internally
		set flags according to the clone() flags ( which resource to share)
		return to do_fork with address of new child
		then choose child to run first
		alloc pid for child
	



in vfork :
	we just fork but not copy even page addressed , parent wait child to exec or exit , accept a signal then continue 
		until that happens ,parent blocked , (differentiate from above by a special flag in clone's flag)



about threads:
	threads are just the same as processes , happen to share some resourceses
	use clone to  set seperate flags

about kernel-threads
	kernel-threads are processed only run in kernel space , can also be scheduled and preempted
	use kthread_create or kthread_run


about exit:
	set flag , release mm and fs statics ,save exit code
	notify parent , reparent children to group's other thread or the init
	change to zonbie status , 
	call schedule ( never return)

about wait
	detach from task list,notify if orphan , release all resources including thread_info and task list


about scheduler:
	we have real-time processes    and    normal processes ,   nornal one has  nice value , real-time has priority
		(nice value not 等差数列 )
	CFS  do with proportitions , when you have used little , then next time you require , you may be 
		sched to run immediately (if same priority) ,
	

how CFS works
	we have a scheduler run  when new process into runable status or blocked or periodically by the system timer , 

	update_curr:
		this func used to update time of a specific schedule entity( a task struct sometime),
			and the whole time of that cfs run queue
	
	enqueue_entity
	dequque_entity:
		used to manipulate red-black tree and the runnable  process queue. when block  exit  start or
			periodically

	in scheduler():
		pick next task -> pick next entity (now you get the next process to run)

switch from sleep and runnable:
	when wait or have lock, you sleep( mark sleep , add into wait queue , delete from rb tree )
	when  wake up , inverse
	
	we have interruptable and uninterruptable sleep , former will wake up when accept a signal


	prepare sleep:
		usually in a loop to avoid indefinite sleep(possibly), and deal with conditions to 
			wake up in the loop conditon or inner the loop
		add wait queue->prepare_to_wait -> loop {scheduler  check} -> finish_wait (the dequeue of
			current process is in schedule() ,in deactivate_task

	wake up:
		programs can call wake up themselves , -> try-to-wake-up -> activate_task(will enqueue task)
		but wake up not means ready to run ,so condition must be checked

	schedule:
		we set need_sched flag to signify kernel to schedule (  set when wake up or schedule_tick(when need
			preempt) , and flag will be checked when returning to user space or return from interrupt , 
			the flag is in per process thread info struct

	preemption:
		user-space-preemption:
			occur when return from interrupt context or kernel space , check need_sched is set , then call schedule()
		kernel-preemption:
			when return from interrupt handler , before into  kernel space(will check the preempt count)
			when preemp count == 0 , (during unlock , will call the check)
			if call schedule
			if a task in kernel block	

		(even in CFS we have time slice ,but it is  given by schedule , and every time schedule(
			when above environments ) that vruntime(timeslice) will add , and will choose the 
			least one to run (use red_black tree))
		
	
		

here comment:
	通常在一个函数或者一个循环的开头部分处理结束等特殊情况，然后才是正常的流程情况"


sched_rr  sched_fifo   sched_normal
	the latter one is nornal processes , use nice value ( in the same region of the priority value ,so 
		do not have meanings at the same time)
	the former two are real time schedulers , fifo  will run every real-time pros one after one ,
		until one give up the process(no preemption , except when higher priority real-time pro can
			preempt it)
		round-robin will run every  same priority real-time pro in a timeslice , but only when same
			priority, low ones can not preempt high ones( until all high ones over, low ones can
			run)
		
	until all real-time have blocked or exited , normals can run

note;
	nice and priority  use the same  region value but different values
	we have some funcs used to set and get real-time or nice values of processes(in LDK page 65)
		we can even set which cpus the process must run on and must not run on 
		and we can yield cpus when needed (same priority  real-time will one add to the end of array)
	





SYSTEM CALLS
	user space interactive with kernel through this

	system calls wrapped by C library , which implements most of POSIX ,
		kernel only provide machanism , not policy

about asmlinkage
	used to notify that this function will receive its params from stack,not register 
	 used only in system call definitions , but unify all archs' syscall convertion
	when  us to kernel space , pushd to stack , then kernel can directly use stack

system call naming
	abc(user) ->  sys_abc(kernel)
	
	every syscall have a number attached to it , can not change ,or other api will fail!!(in arch asm  )
	linux syscall fast  due to fast context switch and simple syscall implement

trap into kernel
	to run kernel code , must use exception to trap into kernel , use int $80  to trigger system_call()

system calls 
	should be defined with explicit destinations 
	use  SYSTEMD_DEFINE to define
	the system call declare and are in the arch dirs ,because they are not generic to all archs 



KERNEL_DATA-STRUCTS
LIST:
	use generic  list , struct list_head ,  have next and prev two members , 
	this list is embeded into the true struct to be linked , referred by list_entry 
		and you can iterate by list for each entry / list_for_each_entry_reverse(every time return
			the next one,not the current one)
		but this is not proper for traverse while delete , should use list for each entry safe
	manipulate by  list add list del  list splice ( add one list into the other one)


QUEUE:
	we have enqueue and dequeue	
	allocated by kfifo_alloc (allocate a queue with specified size)
	or kfifo_init  DECLARE_KFIFO  INIT_FIFO (staticly) 
		(all size must be a power of 2)
	use kfifo_in  kfifo_out  kfifo_out_peek(not remove) to enqueue  dequeue or just peek)
	there are also  size and used /available  size's func of the queue
	free with kfifo_free( kfifo_init use your own buffer , so free yourselves)
	

MAP: (only used to associate a number with pointer , (void*))
	in kernel is called idr( a structure)
	idr_init to init
	to insert a new map relative:
		idr_pre_get()-> idr_get_new/idr_get_new_above
	the former will make resize preparetion , the latter will actually make associations and return the id
		
	use idr_find to return the ptr  of the UID given	
	use idr_remove to remove  and  idr_remove_all to remove all in the map array
	use idr_destroy to destroy the array(but already allocated uid spaces will not free , so call idr_remove_all before this!)

TREE
	binary tree , binary search tree ,  red-black tree , 
	then last one used in kernel , always ensure that any node's  longest child no more than double of the shortest
		child , (why do so, because cheap to realize , 
	rbtree do not implement  insert and find , this will be done by  the developer themselves , because effcient


INTERRUPT 
	interrupt used by hardwares to notify  processor , then it notify kernel , 
	it run in a interrupt context , can not be blocked , used to respond the hardware then tell it to
		continue to work

	workflow:
		network card has data , signify the interrupt controller , 
		controller check if not masked , signify processor , which check if that pin not disabled
		signify kernel , kernel run into special address the do_IRQ func ,the interrupt handler registerd
			by the card copy data from nic buffer to main memory , then return, other work continue
				all others should be done by nic( process data) will be done latter in the 
				bottom half of the procession

	details:
		once processor get signal , it jump to special place corresponding to each interrupt line,
		now kernel can calculte the line number,  then it save registers and call do_IRQ , which
		check validaty and call  handler  , then return to original special entry point;
		which jump to ret_from_intr ,
		then now interrupt handler is over , it will check whether schedule is needed,
		if so , schedule , if not , just restore register and return
			
	drivers register handler and receive an irq number   using request_irq  ,it can sleep , so
		should not be used in interrupt context , should register after initialize hardware
	when free , use free_irq , this will free the unregister the handler , also should specify the
		unique identifier when the interrupt line is shared(must call from process context)
	the interrupt handler is intr_handler()
	
	note: the interrupt handler need not to be reentrant , when running , the current interrupt line 
		is disabled on all processors(others may not if IRQF_DISABLED not set )
	     
	when share same interrupt line:
		set share flag , also handler must have ability to distinguish its own device
		when invoked on a shared line , all handlers on that line will be invoked to try,so
		distinguish is important	

	interrupt context:
		cat not sleep , nor  reschedule , block 
		interrupt my happen when another line's interrupt is being executed
		interrupt stack 2.4 in interruptted process's context , 2.6 in individule processor's space
			should not care

	
QUESTION:
	the book said when return from interrupt , it will check rechedule is needed(need_sched flag set or not)
		if set , call schedule() , 
	but it also said interrupt handler can be interrupted by another interrupt,then if return from the second
	interrupt ,then whether rechedule should happen or not ?


PROCFS
		in /proc/interrupts we can see  cpus , received interrtupts ,controllors and using devices
	
	disable from process:
		process can disable interrupt(also disable preemption at the same time) , 
		also can have lock to prevent other porcesses from accessing same value

		use local_irq_disable local_irq_enable  local_irq_save/restore  to  close or open interrupt
			the save is better than disable due to its saving of the previous value
			ensure the restore  ( only disable the current cpu!!)
		before 2.4 we have cli()  sti() as  global lock , but now deprecated , because not effecient,
		dirver writers must care of the lock and sync

	we can disable a specific interrupt line on all process use  disable_irq  ,(is nested with enable_irq),when shared(lines),
		should not disable (so now pci  devices should not use)
		
		the in_irq  in_interrupt return nonzero if in interrupt context , difference is that the latter one 
			including bottom half portions
	

BOTTOM HALF	
	used to process work the interrupt not done ,because have not enough time
	we now have softirq , tasklets , workqueue three kinds


	
	SOFTIRQ: decided when compile , statically 32 ,when interrupt handler returned , it marked which to run , then
		that will run or be run by the  ksoftirqd daemon or explictly
		
		when pending happens ,  do_softirq will get the pending flag and iterate 32 times to check if
	handler happens ,then do it

	NOTE:  all do_softirqs checked flags are in an order of the enum value in the linux/interrupt.h
		
		both kernel timers and tasklets are built on the  softirq , the former two are dynamically , but
	a little less efficient

	softirq declared enmu priority in include/interrupt.h ,  and bind at runtime by  open_softirq
	
	
	the diff between softirq and tasklet is tasklet can not be run same time on diff processors .

	softirq is raised in handler by raise_sortirq or raise_sortirq_irqoff


	TASKLETS:
		in interrupt handler ,call  tasklet_scheduler() func will  check and set  flag  , then add the tasklet
			into a link list(acctually two , priotity are diff)
		then after return , the do_softirq will check flag (the same as softirq) , and run tasklet_action,
		which will iterate and check(if already run(we have flag) , if disabled),then run, then next ,until list end

		DECLARE_TASKLET   , tasklet_init for statically or dynamically allocate	 , 
				use tasklet_disable/enable to enable or disable the specific tasklet , 
				use tasklet_kill to remove(will sleep , so not called from interrupt env)
	
	softirq and tasklet both can not sleep , so semiphore not used , but can use lock( not sleep)
	
		details: tasklet will mark(by scheduler) only once(even if not have run ,but the second mark comming),	
			if is running, then reschedule and will run again in the future,
			will run on the same processor as the flag marked
			
		
