plot:
	划线：
	matplotlib.pyplot
		scatter 画点
		plot  画线
		xlabel  ylabel
		show  to show
LinearRegression:
	sklearn.linear_model.LinearRegression
	fit(train, result)
	predict(xxx)  这个只能接收list!!

估计：
	score:  r^2 score
		输出由输入所决定的百分比，相性
	可以比较训练和测试集合的分数差
	使用平方和来衡量很不标准，因为数据两大，就会大

Note:
	注意数据的格式，就在文档的shape里面，注意要纵向量的，就是两层数组
	slope 返回 二维数组
	intercept返回一维数组
	predict return 二维数组 , 接受二维数组

最小化误差的方法：
	最小二乘法 这个利用偏导为０，直接的出矩阵形式的结论，计算比较复杂，有时候没哟解释
	梯度下降法 这个逐渐逼近，优势后会有局部最小解
	
	使用平方而不是绝对值，这个对大的差惩罚大，对于支持向量机
		更加有效记录，而且微分性质好

逻辑会对更偏向两边的数给予更加偏向０　或者　１的值，
	让他们的影响更加小，，所有和单单线性回归＞０　＜０是不太等价的

残差平方和 这个就是表示偏差程度的综合，用来梯度下降中找梯度的
均方误差：　这个就是平方和除以ｎ用来表示平均变化程度的
