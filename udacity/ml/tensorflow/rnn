循环神经网络：
	简单来说就是上一次的输出作为这一次输入的一部分，和这一次本来的输入拼起来，
	输出另一方面经过一个神经网络得到最终输出
lstm:
	长短时循环：
	这个有记忆以及丢失门，每当有数据进入，上一个状态进入，上一个输入进入，
		三者共同决定当前的丢弃，以及更新的状态，以及更新的输出，再循环影响，
		长短时的目的是解决语句的依赖中间隔较长的依赖的情况
双向神经网络：
	用于某一时刻的值受到前后影响的时候
深层循环：
	用于需要多层神经网络的循环网络
dropout:
	这个是可以设置的概率，代表了对输入或输出中数据的舍去程度
	用于防止过拟合

loss:
	这两种的损失函数都需要把每一步的损失加入，才能优化所有的损失
	总步数有限制，防止梯度发散
