朴素贝叶斯：
	其实这个就是p(a|b) = p(b|a)*p(a) / (p(b|a)*p(a) + p(b|a~)*p(a~))
	这个在医学检验上很有用
	本质上，只要算出当前状况的乘积乘以当前的概率，
		然后以所有的综合为基准，softmax化即可

	朴素的意思是：
		没有考虑每个元素之间的额顺序，或者说是关系

先验概率：
	就是没开始测试之前的预设概率
后验：
	预测之后的基于的概率p(a|b)b为发生的事情

机器学习中的使用：
	计算每种标签的概率，找到最高的那个，分母可以不要，
	因为所有的都一样，有点像softmax
	p(a|b) =  p(b|a)*p(a) / p(b) 
		这里所有的b都是一样的，然后再假设所有的先验概率都是一样的
		这样我只要p(b|a)就行了，最后得出的那个最大的，也就是这里最大的
	这里的求概率，是假设一种分布，然后利用高斯分布把
		结果和真实标签的结果整理起来
	最大似然估计：
		就是在当前已知的前提下，最大的可能是对的一种假设，
		是利用求各个假设对应的概率
		这个可以用贝叶斯求，然后如果方程是线性的，有噪声，
			利用高斯公式获得相应概率
	最大似然假设是平均先验情况下的最大后验假设
		这个最终转变成方差和最小化计算
p(v|a1a2a3..) = p(a1|v)p(a2|v)... *p(v) / Z
